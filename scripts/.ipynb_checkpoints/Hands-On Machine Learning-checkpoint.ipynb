{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HANDS-ON MACHINE LEARNING\n",
    "\n",
    "Vamos fazer uma atividade prática utilizando dados de expressão do TCGA para 3 tecidos:\n",
    "\n",
    "- COAD (Colon Adenocarcinoma)\n",
    "- READ (Rectum Adenocarcinoma)\n",
    "- STAD (Stomach Adenocarcinoma)\n",
    "\n",
    "Nosso objetivo é verificar se nós conseguimos classificar corretamente 300 amostras aleatórias do TCGA nos tecidos acima mencionados utilizando um modelo específico de machine learning supervisionado, a regressão logística (sim, regressão logística também é machine learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 - Processamento dos dados\n",
    "\n",
    "### Importação de bibliotecas\n",
    "\n",
    "Primeiro, precisamos importar algumas bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for processing\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels import robust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento dos dados\n",
    "\n",
    "Agora, precisamos abrir os arquivos \".tsv\" e selecionar, aleatoriamente, 100 amostras de cada tecido. Nesse exemplo, usamos 100 amostras para termos um tamanho amostral robusto para as análises e para fins de tempo de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open files and get a 100 sample from each\n",
    "# get current directory\n",
    "dirpath = os.getcwd()\n",
    "\n",
    "# read files and get 100 random samples from each\n",
    "df_COAD = pd.read_csv(os.path.join(dirpath + \"/data/GastroTCGA/COAD_PANCAN.tsv\"), delimiter='\\t', index_col=0, header=None)\n",
    "df_COAD = df_COAD.sample(100, axis = 1)\n",
    "df_READ = pd.read_csv(os.path.join(dirpath + \"/data/GastroTCGA/READ_PANCAN.tsv\"), delimiter='\\t', index_col=0, header=None)\n",
    "df_READ = df_READ.sample(100, axis = 1)\n",
    "df_STAD = pd.read_csv(os.path.join(dirpath + \"/data/GastroTCGA/STAD_PANCAN.tsv\"), delimiter='\\t', index_col=0, header=None)\n",
    "df_STAD = df_STAD.sample(100, axis = 1)\n",
    "\n",
    "# merge files\n",
    "df = pd.concat([df_COAD, df_READ, df_STAD], axis=1, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de genes\n",
    "\n",
    "Nessa etapa, nós primeiro calculamos o desvio absoluto da mediana (MAD) da expressão de todos os milhares de genes analisados para os 300 pacientes previamente selecionados.\n",
    "\n",
    "Depois, selecionamos apenas aqueles genes cujo MAD seja alto o suficiente para potencialmente poder explicar a diferença tecidual (COAD, READ ou STAD) entre as amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mad for all genes\n",
    "gene_mad = robust.mad(df.iloc[1:].values.astype(np.float), axis = 1)\n",
    "\n",
    "# prepare final dataframe\n",
    "new_df = pd.DataFrame()\n",
    "new_df = new_df.append(df.iloc[0], ignore_index = True)\n",
    "\n",
    "# get only genes with mad equal or greater then 0.94\n",
    "for i in range(len(gene_mad)):\n",
    "\tif gene_mad[i] >= 0.94:\n",
    "\t\tnew_df=new_df.append(df.iloc[i+1])\n",
    "\n",
    "# save to file\n",
    "new_df.to_csv(os.path.join(dirpath + \"/data/GastroTCGA.tsv\"), sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2 - Classificador\n",
    "\n",
    "Nessa parte é onde a regressão logística de fato ocorre para classificarmos nossas 300 amostras aleatórias em COAD, READ ou STAD de acordo com a expressão gênica.\n",
    "\n",
    "### Importação de bibliotecas\n",
    "\n",
    "Novamente precisamos importar mais algumas outras bibliotecas.\n",
    "\n",
    "A partir daqui começaremos a usar algumas das muitas funcionalidades do SKLEARN. Se tiver curiosidade, acesse o __[link](https://scikit-learn.org/stable/)__ para explorá-lo melhor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import SKLEARN libraries for machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "\n",
    "# import internal library for plotting (check our material for more details)\n",
    "from plot_confusion import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos dados para a classificação\n",
    "\n",
    "Nessa breve etapa, primeiro nós abrimos o arquivo mesclado dos nossos 300 casos aleatórios de pacientes com COAD, READ e STAD com os dados de expressão de genes com MAD elevado.\n",
    "\n",
    "Depois, precisamos extrair as \"características\" a serem utilizadas no modelo (expressão gênica - cada gene é uma característica) para a classificação das amostras.\n",
    "\n",
    "Por fim, precisamos selecionar as \"classes\" (tipo tumoral: COAD, READ ou STAD) a serem utilizadas pelo modelo para classificar as amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open merged file with all the 300 random samples from each tumor type\n",
    "\n",
    "# read merged .tsv file\n",
    "\n",
    "\n",
    "# extract features - gene expression\n",
    "\n",
    "\n",
    "# select classes - tumor type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Classificação com validação \"simples\"*\n",
    "\n",
    "Aqui está o coração do algoritmo (aonde a \"mágica\" ocorre!). Vamos por partes:\n",
    "\n",
    "1. Primeiro, separamos nosso conjunto de dados em 2 partes: o conjunto de treino e o de teste. Usualmente 70% dos dados são utilizados para treino e os outros 30% para teste, mas isso pode variar\n",
    "1. Depois, aplicamos a regressão logística no conjunto de treino para obtermos um modelo ótimo.\n",
    "1. Então, aplicamos nosso modelo para o conjunto de teste\n",
    "1. Por fim, julgamos a eficiência de nosso modelo vendo a sua acurácia.\n",
    "\n",
    "PS: aqui temos alguns conceitos importantes:\n",
    "- Penalidade: tipo de regularização (L1 - Lasso, L2 - Ridge, Elastic-Net, etc...) para penalizar o modelo e evitar \"overfitting\"\n",
    "- \"Solver\": método para encontrarmos os melhores pesos das características para predizer as classes com o menor erro possível (função de custo)\n",
    "- \"Multi class\": temos 3 classes, ou seja, multinomial\n",
    "\n",
    "#### Perguntas\n",
    "\n",
    "- Quantas amostras foram corretamente classificadas? Você achou esse modelo eficiente?\n",
    "- Você percebeu algum viés de classificação? Faz sentido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Simple Validation ####\n",
    "# 70% of the data in the training set and 30% in the test set\n",
    "\n",
    "\n",
    "# call logistic regression\n",
    "\n",
    "\n",
    "# Create an instance of Logistic Regression Classifier and fit the data.\n",
    "\n",
    "\n",
    "# Apply the model on the test set\n",
    "\n",
    "\n",
    "# Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuras\n",
    "\n",
    "Para melhor visualizarmos os resultados do nosso modelo, vamos fazer algumas figuras! Nesse exemplo, vamos fazer um heatmap e uma matriz de confusão.\n",
    "\n",
    "#### Perguntas\n",
    "\n",
    "- Agora você consegue visualizar o suposto viés de classificação desse modelo? Aonde ele ocorre?\n",
    "- Você plotaria algum dos resultados mostrados de outra forma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some plots!\n",
    "\n",
    "# Non-normalized confusion matrix\n",
    "\n",
    "\n",
    "# Normalized confusion matrix\n",
    "\n",
    "\n",
    "# Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Classificação com validação cruzada*\n",
    "\n",
    "A classificação com validação cruzada é um modelo mais robusto para testar a eficiência de seu classificador, especialmente se não há disponibilidade de um conjunto de dados externo (do ICGC, por exemplo) para você desafiar seu modelo. Vamos por partes:\n",
    "\n",
    "1. Explicar passo a passo\n",
    "1. Por fim, novamente julgamos a eficiência de nosso modelo vendo a sua acurácia.\n",
    "\n",
    "#### Perguntas\n",
    "\n",
    "- Quantas amostras foram corretamente classificadas?\n",
    "- Você achou esse modelo mais ou menos eficiente do que o anterior? Por quê?\n",
    "- Você achou esse modelo mais ou menos confiável? Por quê?\n",
    "- Você percebeu algum viés de classificação aqui também? Faz sentido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Cross Validation #####\n",
    "# evaluate the model using 5-fold cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuras\n",
    "\n",
    "Para melhor visualizarmos os resultados desse nosso novo modelo, vamos fazer algumas figuras! Nesse exemplo, vamos novamente fazer um heatmap e uma matriz de confusão a fim de tornar a comparação entre os resultados dos dois modelos mais intuitiva e fácil de interpretar.\n",
    "\n",
    "#### Perguntas\n",
    "\n",
    "- Agora você consegue visualizar o suposto viés de classificação desse modelo? Aonde ele ocorre?\n",
    "- Você plotaria algum dos resultados mostrados de outra forma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some plots!\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "\n",
    "\n",
    "# Heatmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
